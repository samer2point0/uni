{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Image Classification\n",
    "\n",
    "In this lab, you are given a dataset containing 6,000 pictures of cats and dogs (3,000 cats, 3,000 dogs) and asked to train a classifier built upon Convolutional Neural Networks (ConvNets) to classify images as \"dogs\" or \"cats\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 \n",
    "Split the dataset by selecting 4,800 pictures for training, 600 for validation, and 600 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 50\n",
    "img_height = 50\n",
    "num_classes = 2\n",
    "DATA_DIR = './data/'\n",
    "image_filenames = [DATA_DIR+i for i in os.listdir(DATA_DIR)] # use this for full dataset\n",
    "# Split the data in three sets, 80% for training, 10% for validation and 10% for testing\n",
    "# make sure that the image filenames have a fixed order before shuffling\n",
    "# Add your code here\n",
    "\n",
    "random.shuffle(image_filenames)\n",
    "x, y=[],[]\n",
    "\n",
    "#ppedn each image file ot x and each label to y\n",
    "for img in image_filenames:\n",
    "    #reading image into array and then resize it to 50x50 #OPT: interpolation=INTER_AREA\n",
    "    x.append(cv2.resize(cv2.imread(img),(img_height, img_width)))\n",
    "    #use file name to detect label and appaend it to y\n",
    "    if 'cat' in img:\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)\n",
    "\n",
    "#split the dats into trait, test and validation\n",
    "x_train,x_test,x_valid=x[0:4800],x[4800:5400],x[5400:6000]\n",
    "y_train,y_test,y_valid=y[0:4800],y[4800:5400],y[5400:6000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Train a Convolutional Neural Network (ConvNet) on the training set. The general structure of the ConvNet will be a stack of alternated Conv2D (with relu activation) and MaxPooling2D layers. A Conv2D layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. A MaxPooling2D layer is used to downscale input in both the vertical and horizontal dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_69 (Conv2D)           (None, 47, 47, 8)         392       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 47, 47, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 15, 15, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_62 (Flatten)         (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 24)                43224     \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 43,641\n",
      "Trainable params: 43,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 10s 35ms/step - loss: 0.6694 - acc: 0.5775 - val_loss: 0.6187 - val_acc: 0.6757\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 5s 15ms/step - loss: 0.6085 - acc: 0.6633 - val_loss: 0.5742 - val_acc: 0.7123\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 4s 15ms/step - loss: 0.5642 - acc: 0.7117 - val_loss: 0.5561 - val_acc: 0.7140\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 0.5314 - acc: 0.7373 - val_loss: 0.5479 - val_acc: 0.7192\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 0.5069 - acc: 0.7579 - val_loss: 0.5416 - val_acc: 0.7329\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 0.4832 - acc: 0.7702 - val_loss: 0.5473 - val_acc: 0.7226\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 0.4584 - acc: 0.7800 - val_loss: 0.5445 - val_acc: 0.7260\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 0.4317 - acc: 0.7985 - val_loss: 0.5672 - val_acc: 0.7072\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 0.4044 - acc: 0.8131 - val_loss: 0.5734 - val_acc: 0.7123\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 0.3748 - acc: 0.8321 - val_loss: 0.5876 - val_acc: 0.7158\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "batch=16\n",
    "epochs=10\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Conv2D(15,(4,4), input_shape=(img_height,img_width,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Flatten())\n",
    "#add a feedforeward layer with 16 neurons \n",
    "model.add(Dense(25))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "Gen=ImageDataGenerator(rescale=1./255)\n",
    "trainGen=Gen.flow(np.array(x_train), y_train, batch_size=batch, shuffle=False)\n",
    "validGen=Gen.flow(np.array(x_valid), y_valid, batch_size=batch, shuffle=False)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    trainGen, \n",
    "    steps_per_epoch=4800//batch,\n",
    "    epochs=epochs,\n",
    "    validation_data=validGen,\n",
    "    validation_steps=600//batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Output the training/validation loss and accuracy curves. Also print the classification results (e.g., classification accuracy, confusion matrix, precision-recall curves and/or ROC curves) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87      2380\n",
      "           1       0.87      0.87      0.87      2420\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      4800\n",
      "   macro avg       0.87      0.87      0.87      4800\n",
      "weighted avg       0.87      0.87      0.87      4800\n",
      "\n",
      "[[2057  323]\n",
      " [ 310 2110]]\n",
      "0.868125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       310\n",
      "           1       0.66      0.72      0.69       290\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       600\n",
      "   macro avg       0.69      0.69      0.69       600\n",
      "weighted avg       0.69      0.69      0.69       600\n",
      "\n",
      "[[202 108]\n",
      " [ 80 210]]\n",
      "0.6866666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, roc_curve\n",
    "\n",
    "#saving the prediction probabilities in pred_train_y and pred_valid_Y\n",
    "pred_train_y=model.predict(np.array(x_train), batch_size=batch)\n",
    "pred_valid_y=model.predict(np.array(x_valid), batch_size=batch)\n",
    "\n",
    "#outputing the classification report, accuracy and the confusion matrix of the training dataset\n",
    "print(classification_report(y_train,pred_train_y.round()))\n",
    "print(confusion_matrix(y_train,pred_train_y.round()))\n",
    "print(accuracy_score(y_train,pred_train_y.round()))\n",
    "\n",
    "#outputing the classification report, accuracy and the confusion matrix of the validation dataset\n",
    "print(classification_report(y_valid,pred_valid_y.round()))\n",
    "print(confusion_matrix(y_valid,pred_valid_y.round()))\n",
    "print(accuracy_score(y_valid,pred_valid_y.round()))\n",
    "\n",
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Explore different network architectures (e.g., stacking 4 Conv2D+MaxPooling2D layers) and various ways in tuning the model parameters to see if you can improve the model performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_198 (Conv2D)          (None, 48, 48, 16)        448       \n",
      "_________________________________________________________________\n",
      "activation_320 (Activation)  (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_179 (MaxPoolin (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_199 (Conv2D)          (None, 22, 22, 24)        3480      \n",
      "_________________________________________________________________\n",
      "activation_321 (Activation)  (None, 22, 22, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_180 (MaxPoolin (None, 11, 11, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_200 (Conv2D)          (None, 9, 9, 24)          5208      \n",
      "_________________________________________________________________\n",
      "activation_322 (Activation)  (None, 9, 9, 24)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_181 (MaxPoolin (None, 4, 4, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 2, 2, 16)          3472      \n",
      "_________________________________________________________________\n",
      "activation_323 (Activation)  (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_182 (MaxPoolin (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_81 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "activation_324 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_325 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 12,753\n",
      "Trainable params: 12,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 17s 56ms/step - loss: 0.6835 - acc: 0.5527 - val_loss: 0.6688 - val_acc: 0.6081\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 6s 21ms/step - loss: 0.6613 - acc: 0.6008 - val_loss: 0.6520 - val_acc: 0.6216\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 7s 23ms/step - loss: 0.6400 - acc: 0.6298 - val_loss: 0.6217 - val_acc: 0.6729\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 7s 23ms/step - loss: 0.6091 - acc: 0.6650 - val_loss: 0.6067 - val_acc: 0.6627\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 7s 25ms/step - loss: 0.5696 - acc: 0.6992 - val_loss: 0.5712 - val_acc: 0.7140\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 7s 24ms/step - loss: 0.5340 - acc: 0.7256 - val_loss: 0.5294 - val_acc: 0.7483\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 7s 24ms/step - loss: 0.5035 - acc: 0.7512 - val_loss: 0.5225 - val_acc: 0.7414\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 7s 24ms/step - loss: 0.4762 - acc: 0.7692 - val_loss: 0.5563 - val_acc: 0.7089\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 7s 24ms/step - loss: 0.4497 - acc: 0.7904 - val_loss: 0.5458 - val_acc: 0.7226\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 7s 24ms/step - loss: 0.4232 - acc: 0.8004 - val_loss: 0.5400 - val_acc: 0.7209\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "batch=16\n",
    "epochs=10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16,(3,3), input_shape=(img_height,img_width,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(24, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(24, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "#add a feedforeward layer with 16 neurons \n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "Gen=ImageDataGenerator(rescale=1./255)\n",
    "trainGen=Gen.flow(np.array(x_train), y_train, batch_size=batch, shuffle=False)\n",
    "validGen=Gen.flow(np.array(x_valid), y_valid, batch_size=batch, shuffle=False)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    trainGen, \n",
    "    steps_per_epoch=4800//batch,\n",
    "    epochs=epochs,\n",
    "    validation_data=validGen,\n",
    "    validation_steps=600//batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Apply the trained model on the testing set and output the classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.61      0.70       310\n",
      "           1       0.67      0.85      0.75       290\n",
      "\n",
      "   micro avg       0.72      0.72      0.73       600\n",
      "   macro avg       0.74      0.73      0.72       600\n",
      "weighted avg       0.74      0.72      0.72       600\n",
      "\n",
      "[[189 121]\n",
      " [ 44 246]]\n",
      "0.725\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "\n",
    "pred_test_y=model.predict(np.array(x_test), batch_size=batch)\n",
    "#outputing the classification report, accuracy and the confusion matrix of the validation dataset\n",
    "print(classification_report(y_test,pred_test_y.round()))\n",
    "print(confusion_matrix(y_test,pred_test_y.round()))\n",
    "print(accuracy_score(y_test,pred_test_y.round()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6 \n",
    "\n",
    "Plot the saliency map of original image to see which part is important for making classification decisions. You can refer to the following blog article on how to generate visualisation results of the filters in the ConvNets.\n",
    "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
