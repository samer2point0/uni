{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models\n",
    "\n",
    "In this lab, we will explore various regression models for Boston Houses Dataset. We will use regression to predict Boston house prices. We will explore both Ordinary Least Squares and also explore other regression variant of popular classifiers such as decision trees and SVM.\n",
    "\n",
    "We will largely make use of the Scikit-Learn libraries (http://scikit-learn.org/stable/). You can find tutorials and user guide at http://scikit-learn.org/stable/documentation.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "#Array processing\n",
    "import numpy as np\n",
    "\n",
    "#Data analysis, wrangling and common exploratory operations\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "#For visualization. Matplotlib for basic viz and seaborn for more stylish figures + statistical figures not in MPL.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.display import Image\n",
    "\n",
    "from sklearn.datasets import load_boston                                                                       \n",
    "from sklearn.utils import shuffle                                                                                                                                                                      \n",
    "from sklearn import metrics                                                                                                  \n",
    "from sklearn import tree                                                                                                     \n",
    "from sklearn.tree import DecisionTreeRegressor                                                                                                             \n",
    "from sklearn.svm import SVC, LinearSVC , SVR                                                                                 \n",
    "from sklearn.linear_model import LinearRegression                                            \n",
    "from sklearn.ensemble import RandomForestRegressor                                                                                                          \n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score, GridSearchCV                                               \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pydot \n",
    "\n",
    "#######################End imports###################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not make any changes in this cell\n",
    "boston = load_boston()  \n",
    "print(\"Data dimension = \", boston.data.shape) \n",
    "print(\"\\nAttribute names = \", boston.feature_names)\n",
    "print(\"\\nThe median values of house prices (in $1000's), max = %.3f, min = %.3f, average = %.3f,\"\n",
    "      % (np.max(boston.target), np.min(boston.target), np.mean(boston.target)) ) \n",
    "print(\"\\n\", boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not make any changes in this cell.\n",
    "print(\"Data dimension = \", boston.data.shape)\n",
    "print(\"\\nThe first row of data = \", boston.data[0])\n",
    "print(\"\\nTarget dimension = \", boston.target.shape)\n",
    "print(\"\\nBefore transformation: \", np.max(boston.data), np.min(boston.data), np.mean(boston.data))\n",
    "\n",
    "#Split the data into the training set and the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.25, random_state=33)\n",
    "\n",
    "#Scale the data - important for regression. Learn what this function does\n",
    "scalerX = StandardScaler().fit(X_train)\n",
    "scalery = StandardScaler().fit(y_train.reshape(-1, 1))\n",
    "\n",
    "X_train = scalerX.transform(X_train)  \n",
    "y_train = scalery.transform(y_train.reshape(-1, 1))  \n",
    "X_test = scalerX.transform(X_test)    \n",
    "y_test = scalery.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(\"\\nAfter transformation: \", np.max(X_train), np.min(X_train), np.mean(X_train), np.max(y_train), np.min(y_train), np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task t1\n",
    "#Create 13 scatter plots such that variables (CRIM to LSTAT) are in X axis and MEDV in y-axis.\n",
    "#Organize the images such that the images are in 3 rows of 4 images each and 1 in last row\n",
    "\n",
    "#You can refer to http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "#to see how to create scatter plots\n",
    "\n",
    "#Write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not make any change here\n",
    "#To make your life easy, I have created a function that \n",
    "# (a) takes a regressor object,(b) trains it (c) makes some prediction (d) evaluates the prediction\n",
    "def train_and_evaluate(clf, X_train, y_train): \n",
    "    clf.fit(X_train, y_train)   \n",
    "    print(\"Coefficient of determination on training set:\",clf.score(X_train, y_train))\n",
    "    cv = KFold(n_splits=5, random_state=1234, shuffle=True)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv)   \n",
    "    print(\"Average coefficient of determination using 5-fold crossvalidation:\",np.mean(scores))\n",
    "    \n",
    "def plot_regression_fit(actual, predicted):\n",
    "    plt.scatter(actual, predicted)\n",
    "    plt.plot([0, 50], [0, 50], '--k')\n",
    "    plt.axis('tight')\n",
    "    plt.xlabel('True price ($1000s)')\n",
    "    plt.ylabel('Predicted price ($1000s)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task t2\n",
    "#create a regressor object based on LinearRegression\n",
    "# See http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "#Change the following line as appropriate\n",
    "clf_ols = None #change this line\n",
    "\n",
    "train_and_evaluate(clf_ols,X_train,y_train) \n",
    "clf_ols_predicted = clf_ols.predict(X_test) \n",
    "\n",
    "#why using inverse_transform below?\n",
    "plot_regression_fit(scalery.inverse_transform(y_test), scalery.inverse_transform(clf_ols_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task t3\n",
    "#See http://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html\n",
    "\n",
    "#Create a regression based on Support Vector Regressor. Set the kernel to linear\n",
    "#Change the following line as appropriate\n",
    "clf_svr= None   \n",
    "train_and_evaluate(clf_svr,X_train,y_train.ravel()) \n",
    "clf_svr_predicted = clf_svr.predict(X_test) \n",
    "plot_regression_fit(scalery.inverse_transform(y_test), scalery.inverse_transform(clf_svr_predicted))   \n",
    "\n",
    "#Create a regression based on Support Vector Regressor. Set the kernel to polynomial\n",
    "#Change the following line as appropriate\n",
    "clf_svr_poly= None\n",
    "train_and_evaluate(clf_svr_poly,X_train,y_train.ravel()) \n",
    "clf_svr_poly_predicted = clf_svr_poly.predict(X_test)      \n",
    "plot_regression_fit(scalery.inverse_transform(y_test), scalery.inverse_transform(clf_svr_poly_predicted)) \n",
    "\n",
    "#Create a regression based on Support Vector Regressor. Set the kernel to rbf\n",
    "#Change the following line as appropriate\n",
    "clf_svr_rbf= None \n",
    "train_and_evaluate(clf_svr_rbf,X_train,y_train.ravel())\n",
    "clf_svr_rbf_predicted = clf_svr_rbf.predict(X_test)    \n",
    "plot_regression_fit(scalery.inverse_transform(y_test), scalery.inverse_transform(clf_svr_rbf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task t4\n",
    "#See http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html\n",
    "#Create regression tree\n",
    "#Change the following line as appropriate\n",
    "clf_cart = None  \n",
    "train_and_evaluate(clf_cart,X_train,y_train) \n",
    "clf_cart_predicted = clf_cart.predict(X_test)  \n",
    "plot_regression_fit(scalery.inverse_transform(y_test), scalery.inverse_transform(clf_cart_predicted))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task t5\n",
    "#See http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "#Create a random forest regressor with 10 estimators and random state as 1234\n",
    "#Change the following line as appropriate\n",
    "clf_rf= None\n",
    "train_and_evaluate(clf_rf,X_train,y_train.ravel())  \n",
    "\n",
    "#The following prints the most important features\n",
    "std = np.std([tree.feature_importances_ for tree in clf_rf.estimators_],axis=0)\n",
    "indices = np.argsort(clf_rf.feature_importances_)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"\\nFeature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d-%s (%f)\" % (f + 1, indices[f], boston.feature_names[indices[f]], clf_rf.feature_importances_[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), clf_rf.feature_importances_[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "clf_rf_predicted = clf_rf.predict(X_test)      \n",
    "plot_regression_fit(scalery.inverse_transform(y_test), scalery.inverse_transform(clf_rf_predicted)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
