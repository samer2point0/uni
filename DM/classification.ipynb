{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "In this lab, we will be building and evaluating different classifiers for recognising handwritten digits of MNIST dataset. We will be doing the following:\n",
    "\n",
    "1. Binary Classification of MNIST Dataset\n",
    "\n",
    "In the first set of tasks, you will evaluate a number of popular classifiers for the task of recognizing handwritten digits from MNIST dataset. Specifically, we will focus on distinguishing between 7 and 9 which are known to be a hard pair. \n",
    "\n",
    "2. Exploration of Different Evaluation Metrics. \n",
    "\n",
    "In the second set of tasks, you will learn how (and when) to use evaluation metrics for classifiers.\n",
    "\n",
    "3. Parameter Tuning through Grid Search/Cross Validation and Parallelization.\n",
    "\n",
    "You will learn how to tune your classifier and find optimal parameters using grid search. This is a very computationally intensive task - so you will also explore how to leverage parallelization capabilities of IPython kernel to get results sooner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "#Array processing\n",
    "import numpy as np\n",
    "\n",
    "#Data analysis, wrangling and common exploratory operations\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "#For visualization. Matplotlib for basic viz and seaborn for more stylish figures + statistical figures not in MPL.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.display import Image\n",
    "\n",
    "from sklearn.datasets import fetch_mldata                                                                       \n",
    "from sklearn.utils import shuffle                                                                                   \n",
    "from sklearn import metrics                                                                                                  \n",
    "from sklearn import tree                                                                                                     \n",
    "from sklearn.tree import DecisionTreeClassifier                                                       \n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.linear_model import LogisticRegression                                            \n",
    "from sklearn.ensemble import RandomForestClassifier                                                                                                          \n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score, GridSearchCV                                                \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pydot, io\n",
    "import time\n",
    "\n",
    "#######################End imports###################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Binary Classification of MNIST Dataset\n",
    "\n",
    "In the first set of tasks, you will evaluate a number of popular classifiers for the task of recognizing handwritten digits from MNIST dataset. Specifically, we will focus on distinguishing between 7 and 9 which are known to be a hard pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-07fb23d9312f>:12: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "#Images = 65000 and #Pixel per image = 784\n",
      "First image shows 7\n",
      "The corresponding matrix version of image is \n",
      " [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3803922  0.37647063 0.3019608\n",
      " 0.46274513 0.2392157  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3529412\n",
      " 0.5411765  0.9215687  0.9215687  0.9215687  0.9215687  0.9215687\n",
      " 0.9215687  0.9843138  0.9843138  0.9725491  0.9960785  0.9607844\n",
      " 0.9215687  0.74509805 0.08235294 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54901963 0.9843138  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.7411765  0.09019608 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.8862746  0.9960785  0.81568635 0.7803922  0.7803922  0.7803922\n",
      " 0.7803922  0.54509807 0.2392157  0.2392157  0.2392157  0.2392157\n",
      " 0.2392157  0.5019608  0.8705883  0.9960785  0.9960785  0.7411765\n",
      " 0.08235294 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14901961 0.32156864\n",
      " 0.0509804  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.13333334 0.8352942  0.9960785  0.9960785  0.45098042 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32941177\n",
      " 0.9960785  0.9960785  0.9176471  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.32941177 0.9960785  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4156863  0.6156863  0.9960785  0.9960785  0.95294124 0.20000002\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.09803922\n",
      " 0.45882356 0.8941177  0.8941177  0.8941177  0.9921569  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.94117653 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.26666668 0.4666667  0.86274517 0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.5568628  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.14509805 0.73333335 0.9921569\n",
      " 0.9960785  0.9960785  0.9960785  0.8745099  0.8078432  0.8078432\n",
      " 0.29411766 0.26666668 0.8431373  0.9960785  0.9960785  0.45882356\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4431373  0.8588236  0.9960785  0.9490197  0.89019614 0.45098042\n",
      " 0.34901962 0.12156864 0.         0.         0.         0.\n",
      " 0.7843138  0.9960785  0.9450981  0.16078432 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6627451  0.9960785\n",
      " 0.6901961  0.24313727 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.18823531 0.9058824  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07058824 0.48627454 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32941177 0.9960785  0.9960785  0.6509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.54509807\n",
      " 0.9960785  0.9333334  0.22352943 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.8235295  0.9803922  0.9960785  0.65882355\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.9490197  0.9960785  0.93725497 0.22352943 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34901962 0.9843138  0.9450981\n",
      " 0.3372549  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01960784 0.8078432  0.96470594 0.6156863  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01568628 0.45882356\n",
      " 0.27058825 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "The image in grey shape is \n",
      "Shape of data and labels are : (13206, 784) (13206,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00175317 0.00392157 0.00304498\n",
      " 0.00261438 0.00304498 0.00392157 0.00392157 0.00304498 0.00261438\n",
      " 0.00261438 0.00261438 0.00132257 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00044598 0.00087659 0.00132257 0.00132257 0.00132257\n",
      " 0.00132257 0.00132257 0.0021684  0.00261438 0.00261438 0.00261438\n",
      " 0.00392157 0.00261438 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00261438 0.00392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00392157 0.00261438 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00392157 0.00261438 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00392157 0.00261438\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00087659 0.00392157 0.0021684  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00175317\n",
      " 0.00392157 0.00175317 0.00261438 0.00261438 0.00347559 0.00347559\n",
      " 0.00392157 0.00261438 0.00044598 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00132257 0.0021684  0.00261438 0.00392157 0.00392157 0.00392157\n",
      " 0.00392157 0.00261438 0.0021684  0.00132257 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00132257 0.0021684  0.00347559 0.00392157 0.00392157 0.00392157\n",
      " 0.00392157 0.00392157 0.00392157 0.00132257 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00392157 0.00304498\n",
      " 0.00261438 0.00261438 0.00132257 0.         0.         0.00392157\n",
      " 0.00304498 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00392157 0.00261438 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00132257 0.00392157 0.00132257 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00132257 0.00392157\n",
      " 0.00132257 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00132257 0.00392157 0.00087659 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00132257 0.00392157 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00175317 0.00392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00175317 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00347559 0.00392157 0.00044598 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00087659 0.00392157\n",
      " 0.00087659 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################Do not change anything below\n",
    "#Load MNIST data. fetch_mldata will download the dataset and put it in a folder called mldata. \n",
    "#Some things to be aware of:\n",
    "#   The folder mldata will be created in the folder in which you started the notebook\n",
    "#   So to make your life easy, always start IPython notebook from same folder.\n",
    "#   Else the following code will keep downloading MNIST data\n",
    "try:\n",
    "    mnist = fetch_mldata(\"MNIST original\")                                                                                   \n",
    " \n",
    "except Exception as ex: \n",
    "    import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "    m=input_data.read_data_sets(\"MNIST\")\n",
    "    data = np.concatenate((m.train.images, m.test.images))\n",
    "    target = np.concatenate((m.train.labels, m.test.labels))\n",
    "    class dataFrame:\n",
    "        def __init__(self, data, target):\n",
    "            self.data = data\n",
    "            self.target = target\n",
    "    mnist = dataFrame(data, target)\n",
    "\n",
    "#The data is organized as follows:\n",
    "#  Each row corresponds to an image\n",
    "#  Each image has 28*28 pixels which is then linearized to a vector of size 784 (ie. 28*28)\n",
    "# mnist.data gives the image information while mnist.target gives the number in the image\n",
    "print(\"#Images = %d and #Pixel per image = %s\" % (mnist.data.shape[0], mnist.data.shape[1]))\n",
    "\n",
    "#Print first row of the dataset \n",
    "img = mnist.data[0]                                                                                                          \n",
    "print(\"First image shows %d\" % (mnist.target[0]))\n",
    "print(\"The corresponding matrix version of image is \\n\" , img)\n",
    "print(\"The image in grey shape is \")\n",
    "plt.imshow(img.reshape(28, 28), cmap=\"Greys\")                                                                                \n",
    "                                                                                                                             \n",
    "#First 60K images are for training and last 10K are for testing\n",
    "all_train_data = mnist.data[:60000]                                                                                          \n",
    "all_test_data = mnist.data[60000:]                                                                                           \n",
    "all_train_labels = mnist.target[:60000]                                                                                      \n",
    "all_test_labels = mnist.target[60000:]                                                                                       \n",
    "                                                              \n",
    "                                                                                                                             \n",
    "#For the first task, we will be doing binary classification and focus  on two pairs of \n",
    "#  numbers: 7 and 9 which are known to be hard to distinguish\n",
    "#Get all the seven images\n",
    "sevens_data = mnist.data[mnist.target==7]      \n",
    "#Get all the none images\n",
    "nines_data = mnist.data[mnist.target==9]       \n",
    "#Merge them to create a new dataset\n",
    "binary_class_data = np.vstack([sevens_data, nines_data])    \n",
    "binary_class_labels = np.hstack([np.repeat(7, sevens_data.shape[0]), np.repeat(9, nines_data.shape[0])])    \n",
    " \n",
    "#In order to make the experiments repeatable, we will seed the random number generator to a known value\n",
    "# That way the results of the experiments will always be same\n",
    "np.random.seed(1234)                        \n",
    "#randomly shuffle the data\n",
    "binary_class_data, binary_class_labels = shuffle(binary_class_data, binary_class_labels)  \n",
    "print(\"Shape of data and labels are :\" , binary_class_data.shape, binary_class_labels.shape)  \n",
    "\n",
    "#There are approximately 14K images of 7 and 9. \n",
    "#Let us take the first 5000 as training and remaining as test data                                          \n",
    "orig_binary_class_training_data = binary_class_data[:5000]                                                  \n",
    "binary_class_training_labels = binary_class_labels[:5000]                                                   \n",
    "orig_binary_class_testing_data = binary_class_data[5000:]                                                   \n",
    "binary_class_testing_labels = binary_class_labels[5000:] \n",
    "\n",
    "#The images are in grey scale where each number is between 0 to 255\n",
    "# Now let us normalize them so that the values are between 0 and 1. \n",
    "# This will be the only modification we will make to the image\n",
    "binary_class_training_data = orig_binary_class_training_data / 255.0                                        \n",
    "binary_class_testing_data = orig_binary_class_testing_data / 255.0                                          \n",
    "scaled_training_data = all_train_data / 255.0                                                                                \n",
    "scaled_testing_data = all_test_data / 255.0  \n",
    "\n",
    "print(binary_class_training_data[0,:])                                                                 \n",
    "     \n",
    "###########Make sure that you remember the variable names and their meaning\n",
    "#binary_class_training_data, binary_class_training_labels: Normalized images of 7 and 9 and the correct labels for training\n",
    "#binary_class_testing_data, binary_class_testing_labels : Normalized images of 7 and 9 and correct labels for testing\n",
    "#orig_binary_class_training_data, orig_binary_class_testing_data: Unnormalized images of 7 and 9\n",
    "#all_train_data, all_test_data: un normalized images of all digits \n",
    "#all_train_labels, all_test_labels: labels for all digits\n",
    "#scaled_training_data, scaled_testing_data: Normalized version of all_train_data, all_test_data for all digits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification in scikit-learn\n",
    "\n",
    "All classifiers in scikit-learn follow a common pattern that makes life much easier. \n",
    "Follow these steps for all the tasks below.\n",
    "\n",
    "1. Instantiate the classifier with appropriate parameters\n",
    "2. Train/fit the classifier with training data and correct labels\n",
    "3. Test the classifier with unseen data\n",
    "4. Evaluate the performance of classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Decision Trees (10 marks)\n",
    "\n",
    "In the first task, you will use Decision trees (see url\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    ") for classification. \n",
    "\n",
    "Implement a CART decision tree with splitting criterion as entropy. Also print the learned decision tree using the supplied function \"plot_tree\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Do not make any change below\n",
    "def plot_dtree(model,fileName):                                                                                              \n",
    "    #You would have to install a Python package pydot                                                                        \n",
    "    #You would also have to install graphviz for your system - see http://www.graphviz.org/Download..php                     \n",
    "    #If you get any pydot error, see url\n",
    "    # http://stackoverflow.com/questions/15951748/pydot-and-graphviz-error-couldnt-import-dot-parser-loading-of-dot-files-will\n",
    "    dot_tree_data = io.StringIO()                                                                                      \n",
    "    tree.export_graphviz(model, out_file = dot_tree_data)                                                                   \n",
    "    (dtree_graph,) = pydot.graph_from_dot_data(dot_tree_data.getvalue())                                                        \n",
    "    dtree_graph.write_png(fileName)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 (10 marks)\n",
    "# Create a CART decision tree with splitting criterion as entropy\n",
    "# Remember to set the random state to 1234\n",
    "DT=DecisionTreeClassifier(random_state=1234, criterion='entropy')\n",
    "DT.fit(binary_class_training_data, binary_class_training_labels)\n",
    "binary_yDT=DT.predict(binary_class_testing_data)\n",
    "\n",
    "plot_dtree(DT,'DT.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Naive Bayes (10 marks)\n",
    "\n",
    "In this task, you will create a multinomial Naive Bayes classifiers and evaluate it. \n",
    "\n",
    "You might want to use the following url\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 (10 marks)\n",
    "# Create multinomial NB\n",
    "MNB=MultinomialNB()\n",
    "MNB.fit(binary_class_training_data, binary_class_training_labels)\n",
    "binary_yMNB=MNB.predict(binary_class_testing_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Logistic Regression (10 marks)\n",
    "\n",
    "Logistic regression is a simple classifier that converts a regression model into a classification one.\n",
    "You can read the details at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 (10 marks)\n",
    "# Create a model with default parameters. Remember to set random state to 1234\n",
    "LR=LogisticRegression(solver='lbfgs', random_state=1234)\n",
    "LR.fit(binary_class_training_data, binary_class_training_labels)\n",
    "binary_yLR=LR.predict(binary_class_testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Random Forests (10 marks)\n",
    "\n",
    "Random Forests is a very popular ensemble method. See url \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "for details. Implement a Random Forest (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4 (10 marks)\n",
    "# Create a random forest classifier with Default parameters\n",
    "RF=RandomForestClassifier()\n",
    "RF.fit(binary_class_training_data, binary_class_training_labels)\n",
    "binary_yRF=RF.predict(binary_class_testing_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploration of Different Evaluation Metrics for Binary Classification\n",
    "\n",
    "Let us evaluate different metrics for the binary classification models that we created so far. \n",
    "You may want to check the url http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics for additional details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Print the classification results (total: 20 marks)\n",
    "\n",
    "For each of the models above:\n",
    "\n",
    "- Task 5a: Print the classification report and confusion matrix (5 marks)\n",
    "- Task 5b: Print the ROC curve (5 marks)\n",
    "- Task 5c: Print the AUC curve (5 marks)\n",
    "- Task 5d: Print the precision/recall curve (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.97      0.97      0.97      4213\n",
      "           9       0.97      0.97      0.97      3993\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8206\n",
      "   macro avg       0.97      0.97      0.97      8206\n",
      "weighted avg       0.97      0.97      0.97      8206\n",
      "\n",
      "[[4075  138]\n",
      " [ 127 3866]]\n",
      "Multinomial Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.86      0.95      0.91      4213\n",
      "           9       0.94      0.84      0.89      3993\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      8206\n",
      "   macro avg       0.90      0.90      0.90      8206\n",
      "weighted avg       0.90      0.90      0.90      8206\n",
      "\n",
      "[[4009  204]\n",
      " [ 632 3361]]\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.87      0.95      0.91      4213\n",
      "           9       0.94      0.85      0.89      3993\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      8206\n",
      "   macro avg       0.90      0.90      0.90      8206\n",
      "weighted avg       0.90      0.90      0.90      8206\n",
      "\n",
      "[[3993  220]\n",
      " [ 595 3398]]\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.98      0.98      0.98      4213\n",
      "           9       0.98      0.97      0.98      3993\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8206\n",
      "   macro avg       0.98      0.98      0.98      8206\n",
      "weighted avg       0.98      0.98      0.98      8206\n",
      "\n",
      "[[4117   96]\n",
      " [ 102 3891]]\n"
     ]
    }
   ],
   "source": [
    "# task t5a (5 marks)\n",
    "# Print the classification report and confusion matrix for each of the models above\n",
    "# Write code here\n",
    "print('Decision Tree')\n",
    "print(metrics.classification_report(binary_class_testing_labels,binary_yDT))\n",
    "print(metrics.confusion_matrix(binary_class_testing_labels,binary_yDT))\n",
    "print('Multinomial Naive Bayes')\n",
    "print(metrics.classification_report(binary_class_testing_labels,binary_yMNB))\n",
    "print(metrics.confusion_matrix(binary_class_testing_labels,binary_yMNB))\n",
    "print('Logistic Regression')\n",
    "print(metrics.classification_report(binary_class_testing_labels,binary_yLR))\n",
    "print(metrics.confusion_matrix(binary_class_testing_labels,binary_yLR))\n",
    "print('Random Forest')\n",
    "print(metrics.classification_report(binary_class_testing_labels,binary_yRF))\n",
    "print(metrics.confusion_matrix(binary_class_testing_labels,binary_yRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data is not binary and pos_label is not specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6c21caa0da62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AUC for Decision Tree Classifier Predicting Titanic Survivors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mfpr_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_class_testing_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinary_prob_yDT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'false positive rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \"\"\"\n\u001b[1;32m    617\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 618\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/java/python-pip-packages.cs909/lib64/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m              \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m              np.array_equal(classes, [1]))):\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data is not binary and pos_label is not specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mpos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data is not binary and pos_label is not specified"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# task t5b (5 marks)\n",
    "# Each of the model above has some probabilistic interpretation\n",
    "# So sklearn allows you to get the probability values as part of classification\n",
    "# Using this information, you can print roc_curve\n",
    "# See http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson09_decision_trees_random_forests/sklearn_decision_trees.ipynb\n",
    "# Write code here\n",
    "binary_prob_yDT=DT.predict_proba(binary_class_testing_data)[:,0]\n",
    "binary_prob_yMNB=MNB.predict_proba(binary_class_testing_data)\n",
    "binary_prob_yLR=LR.predict_proba(binary_class_testing_data)\n",
    "binary_prob_yRF=RF.predict_proba(binary_class_testing_data)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(10)\n",
    "fig.suptitle('AUC for Decision Tree Classifier Predicting Titanic Survivors')\n",
    "\n",
    "fpr_p, tpr_p, thresholds_p = metrics.roc_curve(binary_class_testing_labels,binary_prob_yDT)\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax1.set_xlabel('false positive rate')\n",
    "ax1.set_ylabel('true positive rate')\n",
    "ax1.plot(fpr_p, tpr_p)\n",
    "\n",
    "fpr_p, tpr_p, thresholds_p = metrics.roc_curve(binary_class_testing_labels,binary_prob_yMNB)\n",
    "ax2 = plt.subplot(2,2, 2)\n",
    "ax2.set_xlabel('false positive rate')\n",
    "ax2.set_ylabel('true positive rate')\n",
    "ax2.plot(fpr_p, tpr_p)\n",
    "\n",
    "fpr_p, tpr_p, thresholds_p = metrics.roc_curve(binary_class_testing_labels,binary_prob_yLR)\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax3.set_xlabel('false positive rate')\n",
    "ax3.set_ylabel('true positive rate')\n",
    "ax3.plot(fpr_p,tpr_p)\n",
    "\n",
    "fpr_p, tpr_p, thresholds_p = metrics.roc_curve(binary_class_testing_labels,binary_prob_yRF)\n",
    "ax4= plt.subplot(2, 2, 4)\n",
    "ax4.set_xlabel('false positive rate')\n",
    "ax4.set_ylabel('true positive rate')\n",
    "ax4.plot(fpr_p, tpr_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task t5c (5 marks)\n",
    "# Print the AUC value for each of the models above\n",
    "# Write code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task t5d (5 marks)\n",
    "# Print the precision recall curve for each of the models above\n",
    "# print the curve based on http://scikit-learn.org/stable/auto_examples/plot_precision_recall.html   \n",
    "# Write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Parameter Tuning through Grid Search/Cross Validation and Parallelization\n",
    "\n",
    "So far in this assignment, you manually tweaked the model till it became better.\n",
    "For complex models, this is often cumbersome. A common trick people use is called Grid Search where you exhaustively test various parameter combinations\n",
    "and pick the best set of parameter values. This is a VERY computationally intensive process and hence it will require some parallelization.\n",
    "\n",
    "In this part, you will learn how to tune Randm Forest for MNIST dataset\n",
    "and then parallelize it so as to get results faster.\n",
    "You might want to take a look at the url\n",
    "http://scikit-learn.org/stable/modules/grid_search.html\n",
    "for additional details.\n",
    "\n",
    "One thing you might want to note is that the GridSearchCV uses cross validation for comparing models.\n",
    "\n",
    "So you have to send the ENTIRE MNIST dataset - i.e. mnist.data and mnist.target. \n",
    "\n",
    "The following cell creates two variables all_scaled_data and all_scaled_target that you can pass to GridSearchCV.\n",
    "\n",
    "In order to get the results in reasonable time, set the **cv** parameter of GridSearchCV to 3.\n",
    "Also remember to set the **verbose** parameter to 2 to get some details about what happens internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Do not make any change below\n",
    "all_scaled_data = binary_class_data / 255.0\n",
    "all_scaled_target = binary_class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Tuning parameters for Random Forest using grid search (15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6 (15 marks)\n",
    "# Tuning Random Forest for MNIST\n",
    "tuned_parameters = [{'max_features': ['sqrt', 'log2'], 'n_estimators': [1000, 1500]}] \n",
    "\n",
    "# Write code here\n",
    "\n",
    "# print the details of the best model and its accuracy\n",
    "# Write code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
